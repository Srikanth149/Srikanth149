{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Srikanth149/Srikanth149/blob/master/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxEUfb9Y2pQC",
        "outputId": "5ae73a7e-bb19-4eb9-ff44-3f3633eb5fcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: llama-cpp-python in /usr/local/lib/python3.11/dist-packages (0.3.9)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.11.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python) (4.13.2)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python) (2.0.2)\n",
            "Requirement already satisfied: diskcache>=5.6.1 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python) (5.6.3)\n",
            "Requirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python) (3.1.6)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.59)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.42)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.4)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.51.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.31.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=2.11.3->llama-cpp-python) (3.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "pip install llama-cpp-python langchain faiss-cpu sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYtKOasC7xl3",
        "outputId": "df6bed44-d982-4614-a7c5-c529b5a3b24f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.24)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.59 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.59)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.25 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.25)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.9.1)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.42)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain-community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain-community) (2.11.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.59->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (2.33.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U langchain-community\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMyO8_vZDoQA",
        "outputId": "73fc1949-82cd-4bbd-8907-d8d0d7748a06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.11/dist-packages (5.5.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WWjTRTuu8J16"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.document_loaders import PyPDFLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bj5vGfB8rCi"
      },
      "outputs": [],
      "source": [
        "loader = PyPDFLoader(\"/content/drive/MyDrive/Nihal.pdf\")\n",
        "docs = loader.load()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4Z01-STDyyf"
      },
      "outputs": [],
      "source": [
        "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "chunks = text_splitter.split_documents(docs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXQjp2aTD4BI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7766f3e-e8b0-4452-8269-b8a79c9b0a33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-fa4e1dacca45>:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJMK6xaKEnIF"
      },
      "outputs": [],
      "source": [
        "db = FAISS.from_documents(chunks, embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FYLGSjIcE3rq"
      },
      "outputs": [],
      "source": [
        "query = \"What are Irrational Numbers?\"\n",
        "retrieved_docs = db.similarity_search(query, k=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vrqRLHzOFOBt"
      },
      "outputs": [],
      "source": [
        "context = \"\\n\".join([doc.page_content for doc in retrieved_docs])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHXCb7W0Fb-s"
      },
      "outputs": [],
      "source": [
        "from llama_cpp import Llama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGQa3xo8Fe-_",
        "outputId": "f43f0195-9219-42b6-e890-14aaf8f1eb74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_model_loader: loaded meta data with 21 key-value pairs and 291 tensors from /content/drive/MyDrive/llama3-8b-instruct-q4_k_m.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = llama-3-8b-instruct\n",
            "llama_model_loader: - kv   2:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   3:                       llama.context_length u32              = 8192\n",
            "llama_model_loader: - kv   4:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
            "llama_model_loader: - kv   6:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   7:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv   8:                       llama.rope.freq_base f32              = 500000.000000\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  10:                          general.file_type u32              = 15\n",
            "llama_model_loader: - kv  11:                           llama.vocab_size u32              = 128256\n",
            "llama_model_loader: - kv  12:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv  13:                       tokenizer.ggml.model str              = gpt2\n",
            "llama_model_loader: - kv  14:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
            "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  16:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
            "llama_model_loader: - kv  17:                tokenizer.ggml.bos_token_id u32              = 128000\n",
            "llama_model_loader: - kv  18:                tokenizer.ggml.eos_token_id u32              = 128001\n",
            "llama_model_loader: - kv  19:                    tokenizer.chat_template str              = {% if not add_generation_prompt is de...\n",
            "llama_model_loader: - kv  20:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q4_K:  193 tensors\n",
            "llama_model_loader: - type q6_K:   33 tensors\n",
            "print_info: file format = GGUF V3 (latest)\n",
            "print_info: file type   = Q4_K - Medium\n",
            "print_info: file size   = 4.58 GiB (4.89 BPW) \n",
            "load: missing pre-tokenizer type, using: 'default'\n",
            "load:                                             \n",
            "load: ************************************        \n",
            "load: GENERATION QUALITY WILL BE DEGRADED!        \n",
            "load: CONSIDER REGENERATING THE MODEL             \n",
            "load: ************************************        \n",
            "load:                                             \n",
            "init_tokenizer: initializing tokenizer for type 2\n",
            "load: control token: 128255 '<|reserved_special_token_250|>' is not marked as EOG\n",
            "load: control token: 128254 '<|reserved_special_token_249|>' is not marked as EOG\n",
            "load: control token: 128253 '<|reserved_special_token_248|>' is not marked as EOG\n",
            "load: control token: 128251 '<|reserved_special_token_246|>' is not marked as EOG\n",
            "load: control token: 128246 '<|reserved_special_token_241|>' is not marked as EOG\n",
            "load: control token: 128243 '<|reserved_special_token_238|>' is not marked as EOG\n",
            "load: control token: 128240 '<|reserved_special_token_235|>' is not marked as EOG\n",
            "load: control token: 128239 '<|reserved_special_token_234|>' is not marked as EOG\n",
            "load: control token: 128238 '<|reserved_special_token_233|>' is not marked as EOG\n",
            "load: control token: 128237 '<|reserved_special_token_232|>' is not marked as EOG\n",
            "load: control token: 128232 '<|reserved_special_token_227|>' is not marked as EOG\n",
            "load: control token: 128228 '<|reserved_special_token_223|>' is not marked as EOG\n",
            "load: control token: 128227 '<|reserved_special_token_222|>' is not marked as EOG\n",
            "load: control token: 128225 '<|reserved_special_token_220|>' is not marked as EOG\n",
            "load: control token: 128222 '<|reserved_special_token_217|>' is not marked as EOG\n",
            "load: control token: 128215 '<|reserved_special_token_210|>' is not marked as EOG\n",
            "load: control token: 128211 '<|reserved_special_token_206|>' is not marked as EOG\n",
            "load: control token: 128210 '<|reserved_special_token_205|>' is not marked as EOG\n",
            "load: control token: 128204 '<|reserved_special_token_199|>' is not marked as EOG\n",
            "load: control token: 128203 '<|reserved_special_token_198|>' is not marked as EOG\n",
            "load: control token: 128201 '<|reserved_special_token_196|>' is not marked as EOG\n",
            "load: control token: 128197 '<|reserved_special_token_192|>' is not marked as EOG\n",
            "load: control token: 128196 '<|reserved_special_token_191|>' is not marked as EOG\n",
            "load: control token: 128195 '<|reserved_special_token_190|>' is not marked as EOG\n",
            "load: control token: 128193 '<|reserved_special_token_188|>' is not marked as EOG\n",
            "load: control token: 128191 '<|reserved_special_token_186|>' is not marked as EOG\n",
            "load: control token: 128190 '<|reserved_special_token_185|>' is not marked as EOG\n",
            "load: control token: 128185 '<|reserved_special_token_180|>' is not marked as EOG\n",
            "load: control token: 128184 '<|reserved_special_token_179|>' is not marked as EOG\n",
            "load: control token: 128182 '<|reserved_special_token_177|>' is not marked as EOG\n",
            "load: control token: 128181 '<|reserved_special_token_176|>' is not marked as EOG\n",
            "load: control token: 128177 '<|reserved_special_token_172|>' is not marked as EOG\n",
            "load: control token: 128176 '<|reserved_special_token_171|>' is not marked as EOG\n",
            "load: control token: 128175 '<|reserved_special_token_170|>' is not marked as EOG\n",
            "load: control token: 128174 '<|reserved_special_token_169|>' is not marked as EOG\n",
            "load: control token: 128173 '<|reserved_special_token_168|>' is not marked as EOG\n",
            "load: control token: 128172 '<|reserved_special_token_167|>' is not marked as EOG\n",
            "load: control token: 128168 '<|reserved_special_token_163|>' is not marked as EOG\n",
            "load: control token: 128167 '<|reserved_special_token_162|>' is not marked as EOG\n",
            "load: control token: 128166 '<|reserved_special_token_161|>' is not marked as EOG\n",
            "load: control token: 128165 '<|reserved_special_token_160|>' is not marked as EOG\n",
            "load: control token: 128162 '<|reserved_special_token_157|>' is not marked as EOG\n",
            "load: control token: 128159 '<|reserved_special_token_154|>' is not marked as EOG\n",
            "load: control token: 128155 '<|reserved_special_token_150|>' is not marked as EOG\n",
            "load: control token: 128153 '<|reserved_special_token_148|>' is not marked as EOG\n",
            "load: control token: 128152 '<|reserved_special_token_147|>' is not marked as EOG\n",
            "load: control token: 128151 '<|reserved_special_token_146|>' is not marked as EOG\n",
            "load: control token: 128148 '<|reserved_special_token_143|>' is not marked as EOG\n",
            "load: control token: 128146 '<|reserved_special_token_141|>' is not marked as EOG\n",
            "load: control token: 128144 '<|reserved_special_token_139|>' is not marked as EOG\n",
            "load: control token: 128143 '<|reserved_special_token_138|>' is not marked as EOG\n",
            "load: control token: 128141 '<|reserved_special_token_136|>' is not marked as EOG\n",
            "load: control token: 128139 '<|reserved_special_token_134|>' is not marked as EOG\n",
            "load: control token: 128138 '<|reserved_special_token_133|>' is not marked as EOG\n",
            "load: control token: 128135 '<|reserved_special_token_130|>' is not marked as EOG\n",
            "load: control token: 128133 '<|reserved_special_token_128|>' is not marked as EOG\n",
            "load: control token: 128132 '<|reserved_special_token_127|>' is not marked as EOG\n",
            "load: control token: 128131 '<|reserved_special_token_126|>' is not marked as EOG\n",
            "load: control token: 128130 '<|reserved_special_token_125|>' is not marked as EOG\n",
            "load: control token: 128128 '<|reserved_special_token_123|>' is not marked as EOG\n",
            "load: control token: 128125 '<|reserved_special_token_120|>' is not marked as EOG\n",
            "load: control token: 128121 '<|reserved_special_token_116|>' is not marked as EOG\n",
            "load: control token: 128120 '<|reserved_special_token_115|>' is not marked as EOG\n",
            "load: control token: 128119 '<|reserved_special_token_114|>' is not marked as EOG\n",
            "load: control token: 128116 '<|reserved_special_token_111|>' is not marked as EOG\n",
            "load: control token: 128112 '<|reserved_special_token_107|>' is not marked as EOG\n",
            "load: control token: 128109 '<|reserved_special_token_104|>' is not marked as EOG\n",
            "load: control token: 128107 '<|reserved_special_token_102|>' is not marked as EOG\n",
            "load: control token: 128106 '<|reserved_special_token_101|>' is not marked as EOG\n",
            "load: control token: 128105 '<|reserved_special_token_100|>' is not marked as EOG\n",
            "load: control token: 128103 '<|reserved_special_token_98|>' is not marked as EOG\n",
            "load: control token: 128100 '<|reserved_special_token_95|>' is not marked as EOG\n",
            "load: control token: 128099 '<|reserved_special_token_94|>' is not marked as EOG\n",
            "load: control token: 128098 '<|reserved_special_token_93|>' is not marked as EOG\n",
            "load: control token: 128094 '<|reserved_special_token_89|>' is not marked as EOG\n",
            "load: control token: 128088 '<|reserved_special_token_83|>' is not marked as EOG\n",
            "load: control token: 128087 '<|reserved_special_token_82|>' is not marked as EOG\n",
            "load: control token: 128086 '<|reserved_special_token_81|>' is not marked as EOG\n",
            "load: control token: 128084 '<|reserved_special_token_79|>' is not marked as EOG\n",
            "load: control token: 128082 '<|reserved_special_token_77|>' is not marked as EOG\n",
            "load: control token: 128078 '<|reserved_special_token_73|>' is not marked as EOG\n",
            "load: control token: 128075 '<|reserved_special_token_70|>' is not marked as EOG\n",
            "load: control token: 128073 '<|reserved_special_token_68|>' is not marked as EOG\n",
            "load: control token: 128072 '<|reserved_special_token_67|>' is not marked as EOG\n",
            "load: control token: 128070 '<|reserved_special_token_65|>' is not marked as EOG\n",
            "load: control token: 128065 '<|reserved_special_token_60|>' is not marked as EOG\n",
            "load: control token: 128064 '<|reserved_special_token_59|>' is not marked as EOG\n",
            "load: control token: 128062 '<|reserved_special_token_57|>' is not marked as EOG\n",
            "load: control token: 128060 '<|reserved_special_token_55|>' is not marked as EOG\n",
            "load: control token: 128059 '<|reserved_special_token_54|>' is not marked as EOG\n",
            "load: control token: 128057 '<|reserved_special_token_52|>' is not marked as EOG\n",
            "load: control token: 128056 '<|reserved_special_token_51|>' is not marked as EOG\n",
            "load: control token: 128054 '<|reserved_special_token_49|>' is not marked as EOG\n",
            "load: control token: 128051 '<|reserved_special_token_46|>' is not marked as EOG\n",
            "load: control token: 128043 '<|reserved_special_token_38|>' is not marked as EOG\n",
            "load: control token: 128042 '<|reserved_special_token_37|>' is not marked as EOG\n",
            "load: control token: 128041 '<|reserved_special_token_36|>' is not marked as EOG\n",
            "load: control token: 128040 '<|reserved_special_token_35|>' is not marked as EOG\n",
            "load: control token: 128035 '<|reserved_special_token_30|>' is not marked as EOG\n",
            "load: control token: 128033 '<|reserved_special_token_28|>' is not marked as EOG\n",
            "load: control token: 128032 '<|reserved_special_token_27|>' is not marked as EOG\n",
            "load: control token: 128029 '<|reserved_special_token_24|>' is not marked as EOG\n",
            "load: control token: 128025 '<|reserved_special_token_20|>' is not marked as EOG\n",
            "load: control token: 128024 '<|reserved_special_token_19|>' is not marked as EOG\n",
            "load: control token: 128021 '<|reserved_special_token_16|>' is not marked as EOG\n",
            "load: control token: 128020 '<|reserved_special_token_15|>' is not marked as EOG\n",
            "load: control token: 128019 '<|reserved_special_token_14|>' is not marked as EOG\n",
            "load: control token: 128018 '<|reserved_special_token_13|>' is not marked as EOG\n",
            "load: control token: 128015 '<|reserved_special_token_10|>' is not marked as EOG\n",
            "load: control token: 128013 '<|reserved_special_token_8|>' is not marked as EOG\n",
            "load: control token: 128012 '<|reserved_special_token_7|>' is not marked as EOG\n",
            "load: control token: 128010 '<|reserved_special_token_5|>' is not marked as EOG\n",
            "load: control token: 128005 '<|reserved_special_token_3|>' is not marked as EOG\n",
            "load: control token: 128004 '<|reserved_special_token_2|>' is not marked as EOG\n",
            "load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG\n",
            "load: control token: 128249 '<|reserved_special_token_244|>' is not marked as EOG\n",
            "load: control token: 128187 '<|reserved_special_token_182|>' is not marked as EOG\n",
            "load: control token: 128180 '<|reserved_special_token_175|>' is not marked as EOG\n",
            "load: control token: 128134 '<|reserved_special_token_129|>' is not marked as EOG\n",
            "load: control token: 128179 '<|reserved_special_token_174|>' is not marked as EOG\n",
            "load: control token: 128037 '<|reserved_special_token_32|>' is not marked as EOG\n",
            "load: control token: 128045 '<|reserved_special_token_40|>' is not marked as EOG\n",
            "load: control token: 128089 '<|reserved_special_token_84|>' is not marked as EOG\n",
            "load: control token: 128212 '<|reserved_special_token_207|>' is not marked as EOG\n",
            "load: control token: 128104 '<|reserved_special_token_99|>' is not marked as EOG\n",
            "load: control token: 128205 '<|reserved_special_token_200|>' is not marked as EOG\n",
            "load: control token: 128142 '<|reserved_special_token_137|>' is not marked as EOG\n",
            "load: control token: 128028 '<|reserved_special_token_23|>' is not marked as EOG\n",
            "load: control token: 128126 '<|reserved_special_token_121|>' is not marked as EOG\n",
            "load: control token: 128198 '<|reserved_special_token_193|>' is not marked as EOG\n",
            "load: control token: 128071 '<|reserved_special_token_66|>' is not marked as EOG\n",
            "load: control token: 128092 '<|reserved_special_token_87|>' is not marked as EOG\n",
            "load: control token: 128183 '<|reserved_special_token_178|>' is not marked as EOG\n",
            "load: control token: 128140 '<|reserved_special_token_135|>' is not marked as EOG\n",
            "load: control token: 128226 '<|reserved_special_token_221|>' is not marked as EOG\n",
            "load: control token: 128007 '<|end_header_id|>' is not marked as EOG\n",
            "load: control token: 128052 '<|reserved_special_token_47|>' is not marked as EOG\n",
            "load: control token: 128053 '<|reserved_special_token_48|>' is not marked as EOG\n",
            "load: control token: 128058 '<|reserved_special_token_53|>' is not marked as EOG\n",
            "load: control token: 128150 '<|reserved_special_token_145|>' is not marked as EOG\n",
            "load: control token: 128149 '<|reserved_special_token_144|>' is not marked as EOG\n",
            "load: control token: 128209 '<|reserved_special_token_204|>' is not marked as EOG\n",
            "load: control token: 128169 '<|reserved_special_token_164|>' is not marked as EOG\n",
            "load: control token: 128157 '<|reserved_special_token_152|>' is not marked as EOG\n",
            "load: control token: 128038 '<|reserved_special_token_33|>' is not marked as EOG\n",
            "load: control token: 128178 '<|reserved_special_token_173|>' is not marked as EOG\n",
            "load: control token: 128091 '<|reserved_special_token_86|>' is not marked as EOG\n",
            "load: control token: 128115 '<|reserved_special_token_110|>' is not marked as EOG\n",
            "load: control token: 128233 '<|reserved_special_token_228|>' is not marked as EOG\n",
            "load: control token: 128145 '<|reserved_special_token_140|>' is not marked as EOG\n",
            "load: control token: 128039 '<|reserved_special_token_34|>' is not marked as EOG\n",
            "load: control token: 128136 '<|reserved_special_token_131|>' is not marked as EOG\n",
            "load: control token: 128170 '<|reserved_special_token_165|>' is not marked as EOG\n",
            "load: control token: 128236 '<|reserved_special_token_231|>' is not marked as EOG\n",
            "load: control token: 128154 '<|reserved_special_token_149|>' is not marked as EOG\n",
            "load: control token: 128049 '<|reserved_special_token_44|>' is not marked as EOG\n",
            "load: control token: 128023 '<|reserved_special_token_18|>' is not marked as EOG\n",
            "load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG\n",
            "load: control token: 128016 '<|reserved_special_token_11|>' is not marked as EOG\n",
            "load: control token: 128113 '<|reserved_special_token_108|>' is not marked as EOG\n",
            "load: control token: 128158 '<|reserved_special_token_153|>' is not marked as EOG\n",
            "load: control token: 128223 '<|reserved_special_token_218|>' is not marked as EOG\n",
            "load: control token: 128156 '<|reserved_special_token_151|>' is not marked as EOG\n",
            "load: control token: 128008 '<|reserved_special_token_4|>' is not marked as EOG\n",
            "load: control token: 128085 '<|reserved_special_token_80|>' is not marked as EOG\n",
            "load: control token: 128160 '<|reserved_special_token_155|>' is not marked as EOG\n",
            "load: control token: 128001 '<|end_of_text|>' is not marked as EOG\n",
            "load: control token: 128110 '<|reserved_special_token_105|>' is not marked as EOG\n",
            "load: control token: 128247 '<|reserved_special_token_242|>' is not marked as EOG\n",
            "load: control token: 128122 '<|reserved_special_token_117|>' is not marked as EOG\n",
            "load: control token: 128050 '<|reserved_special_token_45|>' is not marked as EOG\n",
            "load: control token: 128221 '<|reserved_special_token_216|>' is not marked as EOG\n",
            "load: control token: 128244 '<|reserved_special_token_239|>' is not marked as EOG\n",
            "load: control token: 128248 '<|reserved_special_token_243|>' is not marked as EOG\n",
            "load: control token: 128213 '<|reserved_special_token_208|>' is not marked as EOG\n",
            "load: control token: 128006 '<|start_header_id|>' is not marked as EOG\n",
            "load: control token: 128208 '<|reserved_special_token_203|>' is not marked as EOG\n",
            "load: control token: 128074 '<|reserved_special_token_69|>' is not marked as EOG\n",
            "load: control token: 128234 '<|reserved_special_token_229|>' is not marked as EOG\n",
            "load: control token: 128083 '<|reserved_special_token_78|>' is not marked as EOG\n",
            "load: control token: 128224 '<|reserved_special_token_219|>' is not marked as EOG\n",
            "load: control token: 128055 '<|reserved_special_token_50|>' is not marked as EOG\n",
            "load: control token: 128097 '<|reserved_special_token_92|>' is not marked as EOG\n",
            "load: control token: 128206 '<|reserved_special_token_201|>' is not marked as EOG\n",
            "load: control token: 128081 '<|reserved_special_token_76|>' is not marked as EOG\n",
            "load: control token: 128068 '<|reserved_special_token_63|>' is not marked as EOG\n",
            "load: control token: 128067 '<|reserved_special_token_62|>' is not marked as EOG\n",
            "load: control token: 128046 '<|reserved_special_token_41|>' is not marked as EOG\n",
            "load: control token: 128194 '<|reserved_special_token_189|>' is not marked as EOG\n",
            "load: control token: 128069 '<|reserved_special_token_64|>' is not marked as EOG\n",
            "load: control token: 128000 '<|begin_of_text|>' is not marked as EOG\n",
            "load: control token: 128220 '<|reserved_special_token_215|>' is not marked as EOG\n",
            "load: control token: 128214 '<|reserved_special_token_209|>' is not marked as EOG\n",
            "load: control token: 128108 '<|reserved_special_token_103|>' is not marked as EOG\n",
            "load: control token: 128200 '<|reserved_special_token_195|>' is not marked as EOG\n",
            "load: control token: 128048 '<|reserved_special_token_43|>' is not marked as EOG\n",
            "load: control token: 128027 '<|reserved_special_token_22|>' is not marked as EOG\n",
            "load: control token: 128114 '<|reserved_special_token_109|>' is not marked as EOG\n",
            "load: control token: 128235 '<|reserved_special_token_230|>' is not marked as EOG\n",
            "load: control token: 128252 '<|reserved_special_token_247|>' is not marked as EOG\n",
            "load: control token: 128199 '<|reserved_special_token_194|>' is not marked as EOG\n",
            "load: control token: 128129 '<|reserved_special_token_124|>' is not marked as EOG\n",
            "load: control token: 128245 '<|reserved_special_token_240|>' is not marked as EOG\n",
            "load: control token: 128164 '<|reserved_special_token_159|>' is not marked as EOG\n",
            "load: control token: 128124 '<|reserved_special_token_119|>' is not marked as EOG\n",
            "load: control token: 128102 '<|reserved_special_token_97|>' is not marked as EOG\n",
            "load: control token: 128036 '<|reserved_special_token_31|>' is not marked as EOG\n",
            "load: control token: 128229 '<|reserved_special_token_224|>' is not marked as EOG\n",
            "load: control token: 128163 '<|reserved_special_token_158|>' is not marked as EOG\n",
            "load: control token: 128127 '<|reserved_special_token_122|>' is not marked as EOG\n",
            "load: control token: 128111 '<|reserved_special_token_106|>' is not marked as EOG\n",
            "load: control token: 128231 '<|reserved_special_token_226|>' is not marked as EOG\n",
            "load: control token: 128188 '<|reserved_special_token_183|>' is not marked as EOG\n",
            "load: control token: 128061 '<|reserved_special_token_56|>' is not marked as EOG\n",
            "load: control token: 128137 '<|reserved_special_token_132|>' is not marked as EOG\n",
            "load: control token: 128093 '<|reserved_special_token_88|>' is not marked as EOG\n",
            "load: control token: 128095 '<|reserved_special_token_90|>' is not marked as EOG\n",
            "load: control token: 128189 '<|reserved_special_token_184|>' is not marked as EOG\n",
            "load: control token: 128090 '<|reserved_special_token_85|>' is not marked as EOG\n",
            "load: control token: 128147 '<|reserved_special_token_142|>' is not marked as EOG\n",
            "load: control token: 128219 '<|reserved_special_token_214|>' is not marked as EOG\n",
            "load: control token: 128230 '<|reserved_special_token_225|>' is not marked as EOG\n",
            "load: control token: 128217 '<|reserved_special_token_212|>' is not marked as EOG\n",
            "load: control token: 128031 '<|reserved_special_token_26|>' is not marked as EOG\n",
            "load: control token: 128030 '<|reserved_special_token_25|>' is not marked as EOG\n",
            "load: control token: 128250 '<|reserved_special_token_245|>' is not marked as EOG\n",
            "load: control token: 128192 '<|reserved_special_token_187|>' is not marked as EOG\n",
            "load: control token: 128096 '<|reserved_special_token_91|>' is not marked as EOG\n",
            "load: control token: 128186 '<|reserved_special_token_181|>' is not marked as EOG\n",
            "load: control token: 128207 '<|reserved_special_token_202|>' is not marked as EOG\n",
            "load: control token: 128171 '<|reserved_special_token_166|>' is not marked as EOG\n",
            "load: control token: 128080 '<|reserved_special_token_75|>' is not marked as EOG\n",
            "load: control token: 128077 '<|reserved_special_token_72|>' is not marked as EOG\n",
            "load: control token: 128101 '<|reserved_special_token_96|>' is not marked as EOG\n",
            "load: control token: 128079 '<|reserved_special_token_74|>' is not marked as EOG\n",
            "load: control token: 128216 '<|reserved_special_token_211|>' is not marked as EOG\n",
            "load: control token: 128014 '<|reserved_special_token_9|>' is not marked as EOG\n",
            "load: control token: 128047 '<|reserved_special_token_42|>' is not marked as EOG\n",
            "load: control token: 128202 '<|reserved_special_token_197|>' is not marked as EOG\n",
            "load: control token: 128044 '<|reserved_special_token_39|>' is not marked as EOG\n",
            "load: control token: 128161 '<|reserved_special_token_156|>' is not marked as EOG\n",
            "load: control token: 128017 '<|reserved_special_token_12|>' is not marked as EOG\n",
            "load: control token: 128066 '<|reserved_special_token_61|>' is not marked as EOG\n",
            "load: control token: 128242 '<|reserved_special_token_237|>' is not marked as EOG\n",
            "load: control token: 128118 '<|reserved_special_token_113|>' is not marked as EOG\n",
            "load: control token: 128076 '<|reserved_special_token_71|>' is not marked as EOG\n",
            "load: control token: 128034 '<|reserved_special_token_29|>' is not marked as EOG\n",
            "load: control token: 128241 '<|reserved_special_token_236|>' is not marked as EOG\n",
            "load: control token: 128026 '<|reserved_special_token_21|>' is not marked as EOG\n",
            "load: control token: 128218 '<|reserved_special_token_213|>' is not marked as EOG\n",
            "load: control token: 128063 '<|reserved_special_token_58|>' is not marked as EOG\n",
            "load: control token: 128117 '<|reserved_special_token_112|>' is not marked as EOG\n",
            "load: control token: 128011 '<|reserved_special_token_6|>' is not marked as EOG\n",
            "load: control token: 128022 '<|reserved_special_token_17|>' is not marked as EOG\n",
            "load: control token: 128123 '<|reserved_special_token_118|>' is not marked as EOG\n",
            "load: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
            "load: special tokens cache size = 256\n",
            "load: token to piece cache size = 0.8000 MB\n",
            "print_info: arch             = llama\n",
            "print_info: vocab_only       = 0\n",
            "print_info: n_ctx_train      = 8192\n",
            "print_info: n_embd           = 4096\n",
            "print_info: n_layer          = 32\n",
            "print_info: n_head           = 32\n",
            "print_info: n_head_kv        = 8\n",
            "print_info: n_rot            = 128\n",
            "print_info: n_swa            = 0\n",
            "print_info: n_swa_pattern    = 1\n",
            "print_info: n_embd_head_k    = 128\n",
            "print_info: n_embd_head_v    = 128\n",
            "print_info: n_gqa            = 4\n",
            "print_info: n_embd_k_gqa     = 1024\n",
            "print_info: n_embd_v_gqa     = 1024\n",
            "print_info: f_norm_eps       = 0.0e+00\n",
            "print_info: f_norm_rms_eps   = 1.0e-05\n",
            "print_info: f_clamp_kqv      = 0.0e+00\n",
            "print_info: f_max_alibi_bias = 0.0e+00\n",
            "print_info: f_logit_scale    = 0.0e+00\n",
            "print_info: f_attn_scale     = 0.0e+00\n",
            "print_info: n_ff             = 14336\n",
            "print_info: n_expert         = 0\n",
            "print_info: n_expert_used    = 0\n",
            "print_info: causal attn      = 1\n",
            "print_info: pooling type     = 0\n",
            "print_info: rope type        = 0\n",
            "print_info: rope scaling     = linear\n",
            "print_info: freq_base_train  = 500000.0\n",
            "print_info: freq_scale_train = 1\n",
            "print_info: n_ctx_orig_yarn  = 8192\n",
            "print_info: rope_finetuned   = unknown\n",
            "print_info: ssm_d_conv       = 0\n",
            "print_info: ssm_d_inner      = 0\n",
            "print_info: ssm_d_state      = 0\n",
            "print_info: ssm_dt_rank      = 0\n",
            "print_info: ssm_dt_b_c_rms   = 0\n",
            "print_info: model type       = 8B\n",
            "print_info: model params     = 8.03 B\n",
            "print_info: general.name     = llama-3-8b-instruct\n",
            "print_info: vocab type       = BPE\n",
            "print_info: n_vocab          = 128256\n",
            "print_info: n_merges         = 280147\n",
            "print_info: BOS token        = 128000 '<|begin_of_text|>'\n",
            "print_info: EOS token        = 128001 '<|end_of_text|>'\n",
            "print_info: EOT token        = 128009 '<|eot_id|>'\n",
            "print_info: LF token         = 198 'Ċ'\n",
            "print_info: EOG token        = 128001 '<|end_of_text|>'\n",
            "print_info: EOG token        = 128009 '<|eot_id|>'\n",
            "print_info: max token length = 256\n",
            "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
            "load_tensors: layer   0 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   1 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   2 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   3 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   4 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   5 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   6 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   7 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   8 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   9 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  10 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  11 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  12 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  13 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  14 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  15 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  16 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  17 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  18 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  19 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  20 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  21 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  22 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  23 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  24 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  25 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  26 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  27 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  28 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  29 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  30 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  31 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  32 assigned to device CPU, is_swa = 0\n",
            "load_tensors: tensor 'token_embd.weight' (q4_K) (and 98 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n",
            "load_tensors:  CPU_AARCH64 model buffer size =  3204.00 MiB\n",
            "load_tensors:   CPU_Mapped model buffer size =  4685.30 MiB\n",
            "repack: repack tensor blk.0.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.0.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.0.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.0.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.0.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.1.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.1.attn_k.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.1.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.1.ffn_gate.weight with q4_K_8x8\n",
            "repack: repack tensor blk.1.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.2.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.2.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.2.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.2.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.2.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.3.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.3.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.3.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.3.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.3.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.4.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.4.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.4.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.4.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.4.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.4.ffn_down.weight with q4_K_8x8\n",
            "repack: repack tensor blk.4.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.5.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.5.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.5.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.5.attn_output.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.5.ffn_gate.weight with q4_K_8x8\n",
            "repack: repack tensor blk.5.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.5.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.6.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.6.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.6.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.6.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.6.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.7.attn_q.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.7.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.7.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.7.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.7.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.7.ffn_down.weight with q4_K_8x8\n",
            "repack: repack tensor blk.7.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.8.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.8.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.8.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.8.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.8.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.8.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.8.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.9.attn_q.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.9.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.9.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.9.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.9.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.9.ffn_down.weight with q4_K_8x8\n",
            "repack: repack tensor blk.9.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.10.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.10.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.10.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.10.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.10.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.11.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.11.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.11.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.11.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.11.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.11.ffn_down.weight with q4_K_8x8\n",
            "repack: repack tensor blk.11.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.12.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.12.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.12.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.12.attn_output.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.12.ffn_gate.weight with q4_K_8x8\n",
            "repack: repack tensor blk.12.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.12.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.13.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.13.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.13.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.13.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.13.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.14.attn_q.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.14.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.14.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.14.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.14.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.14.ffn_down.weight with q4_K_8x8\n",
            "repack: repack tensor blk.14.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.15.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.15.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.15.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.15.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.15.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.15.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.15.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.16.attn_q.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.16.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.16.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.16.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.16.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.17.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.17.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.17.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.17.attn_output.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.17.ffn_gate.weight with q4_K_8x8\n",
            "repack: repack tensor blk.17.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.17.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.18.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.18.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.18.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.18.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.18.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.18.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.18.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.19.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.19.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.19.attn_output.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.19.ffn_gate.weight with q4_K_8x8\n",
            "repack: repack tensor blk.19.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.20.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.20.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.20.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.20.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.20.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.20.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.20.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.21.attn_q.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.21.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.21.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.21.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.21.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.22.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.22.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.22.attn_v.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.22.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.22.ffn_gate.weight with q4_K_8x8\n",
            "repack: repack tensor blk.22.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.22.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.23.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.23.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.23.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.23.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.23.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.23.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.23.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.24.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.24.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.24.attn_output.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.24.ffn_gate.weight with q4_K_8x8\n",
            "repack: repack tensor blk.24.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.25.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.25.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.25.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.25.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.25.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.25.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.25.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.26.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.26.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.26.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.26.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.26.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.26.ffn_down.weight with q4_K_8x8\n",
            "repack: repack tensor blk.26.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.27.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.27.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.27.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.27.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.27.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.28.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.28.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.28.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.28.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.28.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.29.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.29.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.29.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.29.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.29.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.30.attn_q.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.30.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.30.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.30.ffn_gate.weight with q4_K_8x8\n",
            "repack: repack tensor blk.30.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.31.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.31.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.31.attn_output.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.31.ffn_gate.weight with q4_K_8x8\n",
            "repack: repack tensor blk.31.ffn_up.weight with q4_K_8x8\n",
            "....................\n",
            "llama_context: constructing llama_context\n",
            "llama_context: n_seq_max     = 1\n",
            "llama_context: n_ctx         = 4096\n",
            "llama_context: n_ctx_per_seq = 4096\n",
            "llama_context: n_batch       = 512\n",
            "llama_context: n_ubatch      = 512\n",
            "llama_context: causal_attn   = 1\n",
            "llama_context: flash_attn    = 0\n",
            "llama_context: freq_base     = 500000.0\n",
            "llama_context: freq_scale    = 1\n",
            "llama_context: n_ctx_per_seq (4096) < n_ctx_train (8192) -- the full capacity of the model will not be utilized\n",
            "set_abort_callback: call\n",
            "llama_context:        CPU  output buffer size =     0.49 MiB\n",
            "create_memory: n_ctx = 4096 (padded)\n",
            "llama_kv_cache_unified: kv_size = 4096, type_k = 'f16', type_v = 'f16', n_layer = 32, can_shift = 1, padding = 32\n",
            "llama_kv_cache_unified: layer   0: dev = CPU\n",
            "llama_kv_cache_unified: layer   1: dev = CPU\n",
            "llama_kv_cache_unified: layer   2: dev = CPU\n",
            "llama_kv_cache_unified: layer   3: dev = CPU\n",
            "llama_kv_cache_unified: layer   4: dev = CPU\n",
            "llama_kv_cache_unified: layer   5: dev = CPU\n",
            "llama_kv_cache_unified: layer   6: dev = CPU\n",
            "llama_kv_cache_unified: layer   7: dev = CPU\n",
            "llama_kv_cache_unified: layer   8: dev = CPU\n",
            "llama_kv_cache_unified: layer   9: dev = CPU\n",
            "llama_kv_cache_unified: layer  10: dev = CPU\n",
            "llama_kv_cache_unified: layer  11: dev = CPU\n",
            "llama_kv_cache_unified: layer  12: dev = CPU\n",
            "llama_kv_cache_unified: layer  13: dev = CPU\n",
            "llama_kv_cache_unified: layer  14: dev = CPU\n",
            "llama_kv_cache_unified: layer  15: dev = CPU\n",
            "llama_kv_cache_unified: layer  16: dev = CPU\n",
            "llama_kv_cache_unified: layer  17: dev = CPU\n",
            "llama_kv_cache_unified: layer  18: dev = CPU\n",
            "llama_kv_cache_unified: layer  19: dev = CPU\n",
            "llama_kv_cache_unified: layer  20: dev = CPU\n",
            "llama_kv_cache_unified: layer  21: dev = CPU\n",
            "llama_kv_cache_unified: layer  22: dev = CPU\n",
            "llama_kv_cache_unified: layer  23: dev = CPU\n",
            "llama_kv_cache_unified: layer  24: dev = CPU\n",
            "llama_kv_cache_unified: layer  25: dev = CPU\n",
            "llama_kv_cache_unified: layer  26: dev = CPU\n",
            "llama_kv_cache_unified: layer  27: dev = CPU\n",
            "llama_kv_cache_unified: layer  28: dev = CPU\n",
            "llama_kv_cache_unified: layer  29: dev = CPU\n",
            "llama_kv_cache_unified: layer  30: dev = CPU\n",
            "llama_kv_cache_unified: layer  31: dev = CPU\n",
            "llama_kv_cache_unified:        CPU KV buffer size =   512.00 MiB\n",
            "llama_kv_cache_unified: KV self size  =  512.00 MiB, K (f16):  256.00 MiB, V (f16):  256.00 MiB\n",
            "llama_context: enumerating backends\n",
            "llama_context: backend_ptrs.size() = 1\n",
            "llama_context: max_nodes = 65536\n",
            "llama_context: worst-case: n_tokens = 512, n_seqs = 1, n_outputs = 0\n",
            "llama_context: reserving graph for n_tokens = 512, n_seqs = 1\n",
            "llama_context: reserving graph for n_tokens = 1, n_seqs = 1\n",
            "llama_context: reserving graph for n_tokens = 512, n_seqs = 1\n",
            "llama_context:        CPU compute buffer size =   296.01 MiB\n",
            "llama_context: graph nodes  = 1094\n",
            "llama_context: graph splits = 1\n",
            "CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | \n",
            "Model metadata: {'tokenizer.chat_template': \"{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}{% else %}{{ eos_token }}{% endif %}\", 'tokenizer.ggml.eos_token_id': '128001', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'llama.context_length': '8192', 'general.name': 'llama-3-8b-instruct', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8', 'general.file_type': '15', 'llama.vocab_size': '128256', 'llama.rope.dimension_count': '128'}\n",
            "Available chat formats from metadata: chat_template.default\n",
            "Using gguf chat template: {% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n",
            "\n",
            "'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "' }}{% else %}{{ eos_token }}{% endif %}\n",
            "Using chat eos_token: <|end_of_text|>\n",
            "Using chat bos_token: <|begin_of_text|>\n"
          ]
        }
      ],
      "source": [
        "llm = Llama(model_path=\"/content/drive/MyDrive/llama3-8b-instruct-q4_k_m.gguf\", n_ctx=4096)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gIAxFY8hGJwc"
      },
      "outputs": [],
      "source": [
        "prompt = f\"\"\"You are an assistant that answers based on given context.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:{query}\n",
        "Give a detailed answer:\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyWdt9vgKVhz",
        "outputId": "2506c031-4b25-4d4c-e0f4-1ba34759ca1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are an assistant that answers based on given context.\n",
            "\n",
            "Context:\n",
            "6 MATHEMATICS\n",
            "20052006 3\n",
            "–5\n",
            "16\n",
            "60\n",
            "999\n",
            "4\n",
            "–8\n",
            "–6625\n",
            "58\n",
            "0\n",
            "27\n",
            "71\n",
            "17\n",
            "981\n",
            "–12\n",
            "13\n",
            "89\n",
            "–6 7\n",
            "2\n",
            "3\n",
            "9\n",
            "14\n",
            "-65\n",
            "–66\n",
            "26\n",
            "-45\n",
            "036\n",
            "19\n",
            "R\n",
            "You already know that there are infinitely many rationals. It turns out that there\n",
            "are infinitely many irrational numbers too. Some examples are:\n",
            "2, 3, 15, , π, 0.10110111011110...\n",
            "Remark :  Recall that when we use the symbol , we assume that it is the\n",
            "positive square root of the number . So 4  = 2, though both 2 and –2 are square\n",
            "roots of 4.\n",
            "Some of the irrational numbers listed above are familiar to you. For example, you\n",
            "have already come across many of the square roots listed above and the number π.\n",
            "The Pythagoreans proved that 2  is irrational. Later in approximately 425 BC,\n",
            "Theodorus of Cyrene showed that 3, 5, 6, 7, 10, 11, 12, 13,  14, 15\n",
            "and 17  are also irrationals. Proofs of irrationality of 2 , 3 , 5 , etc., shall be\n",
            "discussed in Class X.  As to π, it was known to various cultures for thousands of\n",
            "years, it was proved to be irrational by Lambert and Legendre only in the late 1700s.\n",
            "In the next section, we will discuss why 0.10110111011110... and π are irrational.\n",
            "Let us return to the questions raised at the end of\n",
            "the previous section. Remember the bag of rational\n",
            "numbers. If we now put all irrational numbers into\n",
            "the bag, will there be any number left on the number\n",
            "line? The answer is no! It turns out that the collection\n",
            "of all rational numbers and irrational numbers together\n",
            "make up what we call the collection of real numbers,\n",
            "which is denoted by R. Therefore, a real number is either rational or irrational. So, we\n",
            "can say that every real number is represented by a unique point on the number\n",
            "line. Also, ever y point on the number  line r epresents a unique r eal number .\n",
            "This is why we call the number line, the real number line.\n",
            "In the 1870s two German mathematicians,\n",
            "Cantor and Dedekind, showed that :\n",
            "Corresponding to every real number, there is a\n",
            "point on the real number line, and corresponding\n",
            "to every point on the number line, there exists a\n",
            "unique real number.\n",
            "G. Cantor  (1845-1918)\n",
            "Fig. 1.5\n",
            "R. Dedekind (1831-1916)\n",
            "Fig. 1.4\n",
            "Reprint 2025-26\n",
            "24 MATHEMATICS\n",
            "1.6 Summary\n",
            "In this chapter, you have studied the following points:\n",
            "1. A number r is called a rational number, if it can be written in the form p\n",
            "q , where p and q are\n",
            "integers and q ≠ 0.\n",
            "2. A number s is called a irrational number, if it cannot be written in the form p\n",
            "q , where p and\n",
            "q are integers and q ≠ 0.\n",
            "3. The decimal expansion of a rational number is either terminating or non-terminating recurring.\n",
            "Moreover, a number whose decimal expansion is terminating or non-terminating recurring\n",
            "is rational.\n",
            "4. The decimal expansion of an irrational number is non-terminating non-recurring. Moreover,\n",
            "a number whose decimal expansion is non-terminating non-recurring is irrational.\n",
            "5. All the rational and irrational numbers make up the collection of real numbers.\n",
            "6. If r is rational and s is irrational, then r\n",
            " + s and r – s are irrational numbers, and rs and r\n",
            "s  are\n",
            "irrational numbers, r ≠ 0.\n",
            "7. For positive real numbers a and b, the following identities hold:\n",
            "(i) ab a b= (ii) a a\n",
            "b b\n",
            "=\n",
            "(iii) ( ) ( )a b a b a b+ − = − (iv) ( ) ( )\n",
            "2a b a b a b+ − = −\n",
            "(v) ( )\n",
            "2\n",
            "2a b a ab b+ = + +\n",
            "8. To rationalise the denominator of 1 ,\n",
            "a b+  we multiply this by ,a b\n",
            "a b\n",
            "−\n",
            "−\n",
            " where a and b are\n",
            "integers.\n",
            "9. Let a > 0 be a real number and p and q be rational numbers. Then\n",
            "(i) ap . aq = ap + q (ii) (ap)q = apq\n",
            "(iii)\n",
            "p\n",
            "p q\n",
            "q\n",
            "a aa\n",
            "−= (iv) apbp = (ab)p\n",
            "Reprint 2025-26\n",
            "NUMBER SYSTEMS 15\n",
            "1.4 Operations on Real Numbers\n",
            "You have learnt, in earlier classes, that rational numbers satisfy the commutative,\n",
            "associative and distributive laws for addition and multiplication. Moreover, if we add,\n",
            "subtract, multiply or divide (except by zero) two rational numbers, we still get a rational\n",
            "number (that is, rational numbers are ‘closed’ with respect to addition, subtraction,\n",
            "multiplication and division). It turns out that irrational numbers also satisfy the\n",
            "commutative, associative and distributive laws for addition and multiplication. However,\n",
            "the sum, difference, quotients and products of irrational numbers are not always\n",
            "irrational. For example, \n",
            "( ) ( )6 6+ − , ( ) ( ) ( ) ( )2 2 3 3 ,− ⋅  and \n",
            "17\n",
            "17  are\n",
            "rationals.\n",
            "Let us look at what happens when we add and multiply a rational number with an\n",
            "irrational number. For example, 3  is irrational. What about2 3+  and 2 3 ? Since\n",
            "3  has a non-terminating  non-recurring decimal expansion, the same is true for\n",
            "2 3+  and 2 3 . Therefore, both 2 3+  and 2 3  are also irrational numbers.\n",
            "Example 11 : Check whether 7 5 , 7 2 21 2\n",
            "5\n",
            ", ,+ π −  are irrational numbers or\n",
            "not.\n",
            "Solution : 5  = 2.236... , 2  = 1.4142..., π = 3.1415...\n",
            "Then 7 5  = 15.652..., \n",
            "7\n",
            "5  = \n",
            "7 5 7 5\n",
            "55 5\n",
            "=  = 3.1304...\n",
            "2  + 21 = 22.4142..., π – 2 = 1.1415...\n",
            "All these are non-terminating non-recurring decimals. So, all these are irrational numbers.\n",
            "Now, let us see what generally happens if we add, subtract, multiply , divide, take\n",
            "square roots and even nth roots of these irrational numbers, where n is any natural\n",
            "number. Let us look at some examples.\n",
            "Example 12 :  Add 2 2 5 3+  and 2 3 3– .\n",
            "Solution : ( ) ( )2 2 5 3 2 3 3 –+ +  = ( ) ( )2 2 2 5 3 3 3 –+ +\n",
            "                 = (2 + 1) 2 (5 3) 3 3 2 2 3+ − = +\n",
            "Reprint 2025-26\n",
            "\n",
            "Question:What are Irrational Numbers?\n",
            "Give a detailed answer:\n"
          ]
        }
      ],
      "source": [
        "print(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBtS-QFWGgaN",
        "outputId": "06d7d45a-b467-42a5-a2b6-5c0a70ef7e21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =  605598.88 ms\n",
            "llama_perf_context_print: prompt eval time =  605597.68 ms /  1808 tokens (  334.95 ms per token,     2.99 tokens per second)\n",
            "llama_perf_context_print:        eval time =  229099.14 ms /   255 runs   (  898.43 ms per token,     1.11 tokens per second)\n",
            "llama_perf_context_print:       total time =  835166.13 ms /  2063 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "Irrational numbers are real numbers that cannot be expressed as a finite decimal or fraction. In other words, they are numbers that have an infinite number of digits that never repeat in a predictable pattern. Examples of irrational numbers include pi (π), the square root of 2, and the square root of 3. These numbers are called irrational because they cannot be expressed as a simple fraction, such as 1/2 or 3/4, and their decimal expansions go on forever without repeating.\n",
            "\n",
            "Irrational numbers are different from rational numbers, which are numbers that can be expressed as a finite decimal or fraction. Rational numbers include all integers, fractions, and decimals that terminate or repeat in a predictable pattern. For example, the number 3.14 is a rational number because it can be expressed as the fraction 314/100.\n",
            "\n",
            "Irrational numbers were first discovered by ancient Greek mathematicians, who realized that the square root of 2 was not a rational number. This discovery led to the development of irrational numbers and the concept of real numbers, which are numbers that can be expressed as either rational or irrational numbers.\n",
            "\n",
            "Irrational numbers have many important applications in mathematics and science. For example, they are used to describe the lengths of sides of triangles\n"
          ]
        }
      ],
      "source": [
        "output = llm(prompt, max_tokens=256,temperature=0.01,top_p=0.9,stop=None)\n",
        "\n",
        "print(output[\"choices\"][0][\"text\"])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1cZh8mN89GqLUX2j1J3iQT80I7d58kW31",
      "authorship_tag": "ABX9TyNDUCPXdj1siIpycEL1wIXZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}